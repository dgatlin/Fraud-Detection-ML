{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Appled Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics Used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy \n",
    "Is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, we have to look at other parameters to evaluate the performance of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Precision \n",
    "Is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answers is: Of all transactions that were labeled as fraud, how many were actually fraud? \n",
    "\n",
    "Precision = TP/TP+FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall (Sensitivity) \n",
    "Is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the transaction that where truly fraudulent, how many did the model label correctly? \n",
    "\n",
    "Recall = TP/TP+FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Area Under the Precision-Recall Curve (AUPRC)\n",
    "\n",
    "https://www.biostat.wisc.edu/~page/rocpr.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import recall_score,accuracy_score, classification_report,precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the data\n",
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11a37d2e8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEpBJREFUeJzt3X+sX/Vdx/Hna+2Y8wejGx1iiyvOzojoGFRGXDTTRSgkppsOZcvWZhJrFjDOGCMzUZZNEo37oexHDZOOdtnWkbGNGjtrZeg0ssllNvx04cpw3FFpWRHQBRX29o/v57ov5dvb7y393O/19vlITr7n+z6f8zmfkzS8OOd8vuemqpAkqafnTHoAkqSlz7CRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqbvmkB7BYnHzyybVmzZpJD0OS/l+57bbbHq6qlUdqZ9g0a9asYWpqatLDkKT/V5L86zjtvI0mSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSerONwgcQ+f81vZJD0GL0G1/tHHSQ5AmzisbSVJ3ho0kqTvDRpLUnWEjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSequW9gkOS3JzUnuSXJXkl9v9Xck+XqSvW25aGiftyeZTvKVJBcM1de32nSSK4bqpyf5UpJ7k3wyyQmt/rz2fbptX9PrPCVJR9bzyuZJ4Der6oeB84DLkpzRtr2vqs5qyy6Atu0S4EeA9cCHkixLsgz4IHAhcAbwhqF+/rD1tRZ4BLi01S8FHqmqHwTe19pJkiakW9hU1b6q+nJbfxy4B1g1xy4bgB1V9V9V9VVgGji3LdNVdV9V/TewA9iQJMDPAJ9q+28DXjvU17a2/ingNa29JGkCFuSZTbuN9QrgS610eZLbk2xNsqLVVgEPDO0202qHq78I+PeqevKQ+tP6atsfbe0lSRPQPWySfDdwA/C2qnoM2AK8FDgL2Ae8Z7bpiN3rKOpz9XXo2DYnmUoydeDAgTnPQ5J09LqGTZLnMgiaj1XVpwGq6qGqeqqqvgV8mMFtMhhcmZw2tPtq4ME56g8DJyVZfkj9aX217S8ADh46vqq6pqrWVdW6lStXPtvTlSQdRs/ZaAGuBe6pqvcO1U8davY64M62vhO4pM0kOx1YC/wjcCuwts08O4HBJIKdVVXAzcDr2/6bgBuH+trU1l8PfL61lyRNwPIjNzlqrwLeDNyRZG+r/Q6D2WRnMbitdT/wqwBVdVeS64G7Gcxku6yqngJIcjmwG1gGbK2qu1p/vw3sSPL7wD8xCDfa50eTTDO4ormk43lKko6gW9hU1d8z+tnJrjn2uQq4akR916j9quo+vn0bbrj+BHDxfMYrSerHNwhIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuuoVNktOS3JzkniR3Jfn1Vn9hkj1J7m2fK1o9Sa5OMp3k9iRnD/W1qbW/N8mmofo5Se5o+1ydJHMdQ5I0GT2vbJ4EfrOqfhg4D7gsyRnAFcBNVbUWuKl9B7gQWNuWzcAWGAQHcCXwSuBc4Mqh8NjS2s7ut77VD3cMSdIEdAubqtpXVV9u648D9wCrgA3AttZsG/Datr4B2F4DXwROSnIqcAGwp6oOVtUjwB5gfdt2YlXdUlUFbD+kr1HHkCRNwII8s0myBngF8CXglKraB4NAAl7cmq0CHhjababV5qrPjKgzxzEkSRPQPWySfDdwA/C2qnpsrqYjanUU9fmMbXOSqSRTBw4cmM+ukqR56Bo2SZ7LIGg+VlWfbuWH2i0w2uf+Vp8BThvafTXw4BHqq0fU5zrG01TVNVW1rqrWrVy58uhOUpJ0RD1nowW4Frinqt47tGknMDujbBNw41B9Y5uVdh7waLsFths4P8mKNjHgfGB32/Z4kvPasTYe0teoY0iSJmB5x75fBbwZuCPJ3lb7HeAPgOuTXAp8Dbi4bdsFXARMA98E3gJQVQeTvAu4tbV7Z1UdbOtvBa4Dng98ri3McQxJ0gR0C5uq+ntGP1cBeM2I9gVcdpi+tgJbR9SngDNH1L8x6hiSpMnwDQKSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1N1YYZPkpnFqkiSNsnyujUm+A/hO4OQkK4C0TScC39d5bJKkJWLOsAF+FXgbg2C5jW+HzWPABzuOS5K0hMwZNlX1J8CfJPm1qnr/Ao1JkrTEHOnKBoCqen+SnwDWDO9TVds7jUuStISMFTZJPgq8FNgLPNXKBRg2kqQjGitsgHXAGVVVPQcjSVqaxv2dzZ3A9/YciCRp6Ro3bE4G7k6yO8nO2WWuHZJsTbI/yZ1DtXck+XqSvW25aGjb25NMJ/lKkguG6utbbTrJFUP105N8Kcm9ST6Z5IRWf177Pt22rxnzHCVJnYx7G+0dR9H3dcAHeOZznfdV1buHC0nOAC4BfoTBNOu/TvKytvmDwM8CM8CtSXZW1d3AH7a+diT5U+BSYEv7fKSqfjDJJa3dLx3F+CVJx8i4s9H+dr4dV9UX5nFVsQHYUVX/BXw1yTRwbts2XVX3ASTZAWxIcg/wM8AbW5ttDAJxS+vrHa3+KeADSeLzJkmanHFfV/N4ksfa8kSSp5I8dpTHvDzJ7e0224pWWwU8MNRmptUOV38R8O9V9eQh9af11bY/2tpLkiZkrLCpqu+pqhPb8h3ALzC4RTZfWxhMoT4L2Ae8p9Uzom0dRX2uvp4hyeYkU0mmDhw4MNe4JUnPwlG99bmqPsvgNtZ893uoqp6qqm8BH+bbt8pmgNOGmq4GHpyj/jBwUpLlh9Sf1lfb/gLg4GHGc01VrauqdStXrpzv6UiSxjTujzp/fujrcxj87mbez0CSnFpV+9rX1zGYUg2wE/h4kvcymCCwFvhHBlcpa5OcDnydwSSCN1ZVJbkZeD2wA9gE3DjU1ybglrb98z6vkaTJGnc22s8NrT8J3M/gQfxhJfkE8GoGb4yeAa4EXp3kLAZBdT+DF31SVXcluR64u/V/WVU91fq5HNgNLAO2VtVd7RC/DexI8vvAPwHXtvq1wEfbJIODDAJKkjRB485Ge8t8O66qN4woXzuiNtv+KuCqEfVdwK4R9fv49m244foTwMXzGqwkqatxZ6OtTvKZ9iPNh5LckGR178FJkpaGcScIfITBs5DvYzC1+M9bTZKkIxo3bFZW1Ueq6sm2XAc4fUuSNJZxw+bhJG9KsqwtbwK+0XNgkqSlY9yw+WXgF4F/Y/BjzNcD8540IEk6Po079fldwKaqegQgyQuBdzMIIUmS5jTulc2PzQYNQFUdBF7RZ0iSpKVm3LB5ztBLM2evbMa9KpIkHefGDYz3AP+Q5FMMfv3/i4z4AaYkSaOM+waB7UmmGLx8M8DPtz9gJknSEY19K6yFiwEjSZq3o/oTA5IkzYdhI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKm7bmGTZGuS/UnuHKq9MMmeJPe2zxWtniRXJ5lOcnuSs4f22dTa35tk01D9nCR3tH2uTpK5jiFJmpyeVzbXAesPqV0B3FRVa4Gb2neAC4G1bdkMbIFBcABXAq8EzgWuHAqPLa3t7H7rj3AMSdKEdAubqvoCcPCQ8gZgW1vfBrx2qL69Br4InJTkVOACYE9VHayqR4A9wPq27cSquqWqCth+SF+jjiFJmpCFfmZzSlXtA2ifL271VcADQ+1mWm2u+syI+lzHkCRNyGKZIJARtTqK+vwOmmxOMpVk6sCBA/PdXZI0poUOm4faLTDa5/5WnwFOG2q3GnjwCPXVI+pzHeMZquqaqlpXVetWrlx51CclSZrbQofNTmB2Rtkm4Mah+sY2K+084NF2C2w3cH6SFW1iwPnA7rbt8STntVloGw/pa9QxJEkTsrxXx0k+AbwaODnJDINZZX8AXJ/kUuBrwMWt+S7gImAa+CbwFoCqOpjkXcCtrd07q2p20sFbGcx4ez7wubYwxzEkSRPSLWyq6g2H2fSaEW0LuOww/WwFto6oTwFnjqh/Y9QxJEmTs1gmCEiSljDDRpLUnWEjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLUnWEjSerOsJEkdTeRsElyf5I7kuxNMtVqL0yyJ8m97XNFqyfJ1Ummk9ye5Oyhfja19vcm2TRUP6f1P932zcKfpSRp1iSvbH66qs6qqnXt+xXATVW1FripfQe4EFjbls3AFhiEE3Al8ErgXODK2YBqbTYP7be+/+lIkg5nMd1G2wBsa+vbgNcO1bfXwBeBk5KcClwA7Kmqg1X1CLAHWN+2nVhVt1RVAduH+pIkTcCkwqaAv0pyW5LNrXZKVe0DaJ8vbvVVwAND+8602lz1mRH1Z0iyOclUkqkDBw48y1OSJB3O8gkd91VV9WCSFwN7kvzzHG1HPW+po6g/s1h1DXANwLp160a2kSQ9exO5sqmqB9vnfuAzDJ65PNRugdE+97fmM8BpQ7uvBh48Qn31iLokaUIWPGySfFeS75ldB84H7gR2ArMzyjYBN7b1ncDGNivtPODRdpttN3B+khVtYsD5wO627fEk57VZaBuH+pIkTcAkbqOdAnymzUZeDny8qv4yya3A9UkuBb4GXNza7wIuAqaBbwJvAaiqg0neBdza2r2zqg629bcC1wHPBz7XFknShCx42FTVfcDLR9S/AbxmRL2Ayw7T11Zg64j6FHDmsx6sJOmYWExTnyVJS5RhI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHW3ZMMmyfokX0kyneSKSY9Hko5nSzJskiwDPghcCJwBvCHJGZMdlSQdv5Zk2ADnAtNVdV9V/TewA9gw4TFJ0nFr+aQH0Mkq4IGh7zPAKyc0FmnivvbOH530ELQIff/v3bFgx1qqYZMRtXpGo2QzsLl9/Y8kX+k6quPLycDDkx7EYpB3b5r0EPR0/tucdeWo/1TO20vGabRUw2YGOG3o+2rgwUMbVdU1wDULNajjSZKpqlo36XFIh/Lf5mQs1Wc2twJrk5ye5ATgEmDnhMckScetJXllU1VPJrkc2A0sA7ZW1V0THpYkHbeWZNgAVNUuYNekx3Ec8/akFiv/bU5Aqp7x3FySpGNqqT6zkSQtIoaNjilfE6TFKsnWJPuT3DnpsRyPDBsdM74mSIvcdcD6SQ/ieGXY6FjyNUFatKrqC8DBSY/jeGXY6Fga9ZqgVRMai6RFxLDRsTTWa4IkHX8MGx1LY70mSNLxx7DRseRrgiSNZNjomKmqJ4HZ1wTdA1zva4K0WCT5BHAL8ENJZpJcOukxHU98g4AkqTuvbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNNQJLvTbIjyb8kuTvJriQv843EWqqW7F/qlBarJAE+A2yrqkta7SzglIkOTOrIKxtp4f008D9V9aezharay9BLTJOsSfJ3Sb7clp9o9VOTfCHJ3iR3JvnJJMuSXNe+35HkNxb+lKS5eWUjLbwzgduO0GY/8LNV9USStcAngHXAG4HdVXVV+/tB3wmcBayqqjMBkpzUb+jS0TFspMXpucAH2u21p4CXtfqtwNYkzwU+W1V7k9wH/ECS9wN/AfzVREYszcHbaNLCuws45whtfgN4CHg5gyuaE+D//gDYTwFfBz6aZGNVPdLa/Q1wGfBnfYYtHT3DRlp4nweel+RXZgtJfhx4yVCbFwD7qupbwJuBZa3dS4D9VfVh4Frg7CQnA8+pqhuA3wXOXpjTkMbnbTRpgVVVJXkd8MdJrgCeAO4H3jbU7EPADUkuBm4G/rPVXw38VpL/Af4D2Mjgr6F+JMns/zy+vftJSPPkW58lSd15G02S1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKm7/wUc2kSoFiJlvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot the distribution of data\n",
    "%matplotlib inline\n",
    "sns.countplot(x='Class', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph you can observe that data is really skewed for class 0 which indicates the non fradulant transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Split  \n",
    "\n",
    "Inmportant Note: We should never balance the entire data set using SMOTE or other Up/Down-Sampling techniques before splitting the data into test and train. Doing so we would leak the information in the test data set into training data set. This messes up generalization of the model. Instead we need to split the data first and then use SMOTE or any up/down-sampling method. This eliminates leaking the information from test set into the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normal_amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df = df.drop(['Amount','Time'], axis=1)\n",
    "X = df.loc[:,df.columns != 'Class']\n",
    "y = df.loc[:,df.columns == 'Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below trains a Random Forest model on original data. As you can observe from the output, recall is pretty poor. But accuracy is pretty high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Line Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994382219725431\n",
      "0.7414965986394558\n",
      "0.9159663865546218\n"
     ]
    }
   ],
   "source": [
    "# Calculate the recall score for logistic Regression on Skewed data\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=12)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area Under the Precision-Recall Curve (AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Randomized Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "params = { 'bootstrap': [True, False],\n",
    "            'max_depth': [10, 20, 30, 40, None],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'n_estimators': [200, 400]\n",
    "}\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Rearch of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#clf = GridSearchCV(estimator=rf, param_grid=random_grid, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the recall, let's implement undersampling. Here the code is trying to reduce the number of non fraudulent transactions equivalent to fraudulent ones. The way we will under sample the dataset will be by creating a 50/50 ratio. This will be done by randomly selecting \"x\" amount of sample from the majority class, being \"x\" the total number of records with the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "no_frauds = len(df[df['Class'] == 1])\n",
    "non_fraud_indices = df[df.Class == 0].index\n",
    "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n",
    "fraud_indices = df[df.Class == 1].index\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
    "under_sample = df.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the distribution of data for undersampling\n",
    "%matplotlib inline\n",
    "sns.countplot(x='Class', data=under_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under = under_sample.loc[:,under_sample.columns != 'Class']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'Class']\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code trains the logistic regression on undersampled data. From the result, you can observe that the recall is much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_under = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "rf_under.fit(X_under_train,y_under_train)\n",
    "y_under_pred = rf_under.predict(X_under_test)\n",
    "print(accuracy_score(y_under_test,y_under_pred))\n",
    "print(recall_score(y_under_test,y_under_pred))\n",
    "print(precision_score(y_under_test,y_under_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_under = average_precision_score(y_under_test,y_under_pred)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_under_test,y_under_pred)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Generalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also generalises good enough for full data. With only recall and accuracy used as the metrics to evaluate the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recall for the full data\n",
    "y_pred_full = rf_under.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_full))\n",
    "print(recall_score(y_test,y_pred_full))\n",
    "print(precision_score(y_test, y_pred_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Area Under the Precision-Recall Curve (AUPRC)\n",
    "Here we test how well the model generalized over the entire data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_precision_under_general = average_precision_score(y_test,y_pred_full)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test,y_pred_full)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision_under_general))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "This method of over-sampling the minority class involves creating synthetic minority class examples, and training the model on the new data set. \n",
    "\n",
    "https://arxiv.org/pdf/1106.1813.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_sm = RandomForestClassifier(n_estimators=25, random_state=0)\n",
    "clf_rf_sm.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote = clf_rf_sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation Results')\n",
    "print(clf_rf_sm.score(X_test, y_test))\n",
    "print(recall_score(y_test, y_pred_smote))\n",
    "print(precision_score(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_precision_smote = average_precision_score(y_test,y_pred_smote)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test,y_pred_smote)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because positive is the minority class. There are a lot of negative examples that could become false positives. Conversely, there are fewer positive examples that could become false negatives.\n",
    "\n",
    "Sensitivity (True Positive Rate) is related to False Positive Rate (1-specificity) as visualized by an ROC curve. At one extreme, you call every example positive and have a 100% sensitivity with 100% FPR. At another, you call no example positive and have a 0% sensitivity with a 0% FPR. When the positive class is the minority, even a relatively small FPR (which you may have because you have a high recall=sensitivity=TPR) will end up causing a high number of FPs (because there are so many negative examples).\n",
    "\n",
    "It might be the case that even though the classifier has low precision, it could lead to a very useful probability estimate. For example, just knowing that a hard drive might have a 500 fold increased probability of failing, even though the absolute probability is fairly small, might be important information.\n",
    "\n",
    "Also, a low precision essentially means that the classifier returns a lot of false positives. This however might not be so bad if a false positive is cheap.\n",
    "\n",
    "We are very interested in the recall score, because that is the metric that will help us try to capture the most fraudulent transactions. If you think how Accuracy, Precision and Recall work for a confusion matrix, recall would be the most interesting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
